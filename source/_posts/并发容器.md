---
title: 并发容器
date: 2019-05-05 12:35:45
update: 2019-05-05 12:35:45
categories: 并发编程
tags: [并发编程]
---

### `HashMap`和`HashTable`

Hashmap多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。
HashTable使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。
putIfAbsent() ：没有这个值则放入map，有这个值则返回key本来对应的值。

<!-- more -->

### 并发容器

> Hash

散列，哈希：把任意长度的输入通过一种算法（散列），变换成为固定长度的输出，这个输出值就是散列值。属于压缩映射，容易产生哈希冲突。`Hash`算法有直接取余法等。
产生哈希冲突时解决办法：开放寻址；2、再散列；3、链地址法（相同hash值的元素用链表串起来）。
`ConcurrentHashMap`在发生hash冲突时采用了链地址法。
`md4`,`md5`,`sha-hash`算法也属于`hash`算法，又称摘要算法。

> 位运算

```java
import java.io.UnsupportedEncodingException;

/**
 * 类说明：演示位运算
 */
public class IntToBinary {

    public static void main(String[] args) throws UnsupportedEncodingException {

        int data = 4;
        System.out.println("the 4 is " + Integer.toBinaryString(data));

        //位与  &(1&1=1 1&0=0 0&0=0)
        System.out.println("the 4 is " + Integer.toBinaryString(4));
        System.out.println("the 6 is " + Integer.toBinaryString(6));
        System.out.println("the 4&6 is " + Integer.toBinaryString(4 & 6));
        //位或 | (1|1=1 1|0=1 0|0=0)
        System.out.println("the 4|6 is " + Integer.toBinaryString(4 | 6));
        //位非~（~1=0  ~0=1）
        System.out.println("the ~4 is " + Integer.toBinaryString(~4));
        //位异或 ^ (1^1=0 1^0=1 0^0=0)
        System.out.println("the 4^6 is " + Integer.toBinaryString(4 ^ 6));

        // <<有符号左移 >>有符号的右移  >>>无符号右移

        //取模的操作 a % (2^n) 等价于 a&(2^n-1)
        System.out.println("the 345 % 16 is " + (345 % 16) + " or " + (345 & (16 - 1)));

    }
}
```

使用位运算进行权限配置

```java
/**
 * 类说明：
 */
public class Permission {

    // 是否允许查询，二进制第1位，0表示否，1表示是  
    public static final int ALLOW_SELECT = 1 << 0; // 0001  = 1

    // 是否允许新增，二进制第2位，0表示否，1表示是  
    public static final int ALLOW_INSERT = 1 << 1; // 0010  = 2

    // 是否允许修改，二进制第3位，0表示否，1表示是  
    public static final int ALLOW_UPDATE = 1 << 2; // 0100  =4

    // 是否允许删除，二进制第4位，0表示否，1表示是  
    public static final int ALLOW_DELETE = 1 << 3; // 1000  = 8
    // 存储目前的权限状态  
    private int flag;

    //设置用户的权限
    public void setPer(int per) {
        flag = per;
    }

    //增加用户的权限（1个或者多个）
    public void enable(int per) {
        flag = flag | per;
    }

    //删除用户的权限（1个或者多个）
    public void disable(int per) {
        flag = flag & ~per;
    }

    //判断用户的权限
    public boolean isAllow(int per) {
        return ((flag & per) == per);
    }

    //判断用户没有的权限
    public boolean isNotAllow(int per) {
        return ((flag & per) == 0);
    }

    public static void main(String[] args) {
        int flag = 15;
        Permission permission = new Permission();
        permission.setPer(flag);
        permission.disable(ALLOW_DELETE | ALLOW_INSERT);
        System.out.println("select = " + permission.isAllow(ALLOW_SELECT));
        System.out.println("update = " + permission.isAllow(ALLOW_UPDATE));
        System.out.println("insert = " + permission.isAllow(ALLOW_INSERT));
        System.out.println("delete = " + permission.isAllow(ALLOW_DELETE));
    }
}
```

位运算使用场景：权限控制，物品的属性的保存

### 1.7JDK中`ConcurrentHashMap`中的数据结构

`ConcurrentHashMap`是由`Segment`数组结构和`HashEntry`数组结构组成。`Segment`实际继承自可重入锁（`ReentrantLock`），在`ConcurrentHashMap`里扮演锁的角色；`HashEntry`则用于存储键值对数据。一个`ConcurrentHashMap`里包含一个`Segment`数组，每个`Segment`里包含一个`HashEntry`数组，我们称之为`table`，每个`HashEntry`是一个链表结构的元素。

![并发容器_a](https://volc1612.gitee.io/blog/images/并发容器/并发容器_a.png)

###  面试常问

#### ConcurrentHashMap实现原理是怎么样的或者问ConcurrentHashMap如何在保证高并发下线程安全的同时实现了性能提升？

答：ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了**锁分离**技术。它使用了多个锁来控制对hash表的不同部分进行的修改。内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，只要多个修改操作发生在不同的段上，它们就可以并发进行。

#### 初始化做了什么事？

初始化有三个参数
`initialCapacity`：初始容量大小 ，默认16。
`loadFactor`: 扩容因子，默认0.75，当一个Segment存储的元素数量大于initialCapacity* loadFactor时，该Segment会进行一次扩容。
`concurrencyLevel`: 并发度，默认16。并发度可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。

#### 构造方法中部分代码解惑

* ![并发容器_b](https://volc1612.gitee.io/blog/images/并发容器/并发容器_b.png)

保证Segment数组的大小，一定为2的幂，例如用户设置并发度为17，则实际Segment数组大小则为32

* ![并发容器_c](https://volc1612.gitee.io/blog/images/并发容器/并发容器_c.png)

保证每个Segment中tabel数组的大小，一定为2的幂，初始化的三个参数取默认值时，table数组大小为2

* ![并发容器_d](https://volc1612.gitee.io/blog/images/并发容器/并发容器_d.png)

初始化Segment数组，并实际只填充Segment数组的第0个元素。

* ![并发容器_e](https://volc1612.gitee.io/blog/images/并发容器/并发容器_e.png)

用于定位元素所在segment。segmentShift表示偏移位数，通过前面的int类型的位的描述我们可以得知，int类型的数字在变大的过程中，低位总是比高位先填满的，为保证元素在segment级别分布的尽量均匀，计算元素所在segment时，总是取hash值的高位进行计算。segmentMask作用就是为了利用位运算中取模的操作：	a % (Math.pow(2,n)) 等价于 a&( Math.pow(2,n)-1)

#### 在get和put操作中，是如何快速定位元素放在哪个位置的？

对于某个元素而言，一定是放在某个segment元素的某个table元素中的，所以在定位上，
`定位segment`：取得key的hashcode值进行一次再散列（通过Wang/Jenkins算法），拿到再散列值后，以再散列值的高位进行取模得到当前元素在哪个segment上。

![并发容器_f](https://volc1612.gitee.io/blog/images/并发容器/并发容器_f.png)
![并发容器_g](https://volc1612.gitee.io/blog/images/并发容器/并发容器_g.png)

`定位table`：同样是取得key的再散列值以后，用再散列值的全部和table的长度进行取模，得到当前元素在table的哪个元素上

![并发容器_h](https://volc1612.gitee.io/blog/images/并发容器/并发容器_h.png)

#### get()方法

定位segment和定位table后，依次扫描这个table元素下的的链表，要么找到元素，要么返回null。

##### 在高并发下的情况下如何保证取得的元素是最新的？

答：用于存储键值对数据的HashEntry，在设计上它的成员变量value等都是volatile类型的，这样就保证别的线程对value值的修改，get方法可以马上看到。

![并发容器_i](https://volc1612.gitee.io/blog/images/并发容器/并发容器_i.png)

#### put()方法

1、首先定位segment，当这个segment在map初始化后，还为null，由ensureSegment方法负责填充这个segment。
2、对Segment 加锁

![并发容器_j](https://volc1612.gitee.io/blog/images/并发容器/并发容器_j.png)

3、定位所在的table元素，并扫描table下的链表，找到时：

![并发容器_k](https://volc1612.gitee.io/blog/images/并发容器/并发容器_k.png)

没有找到时：

![并发容器_l](https://volc1612.gitee.io/blog/images/并发容器/并发容器_l.png)

#### 扩容操作

`Segment`不扩容，扩容下面的`table`数组，每次都是将数组翻倍

![并发容器_m](https://volc1612.gitee.io/blog/images/并发容器/并发容器_m.png)

带来的好处

![并发容器_n](https://volc1612.gitee.io/blog/images/并发容器/并发容器_n.png)

可以看见 hash值为34和56的下标保持不变，而15,23,77的下标都是在原来下标的基础上+4即可，可以快速定位和减少重排次数。

#### size()方法

size的时候进行两次不加锁的统计，两次一致直接返回结果，不一致，重新加锁再次统计

### 弱一致性

get方法和containsKey方法都是通过对链表遍历判断是否存在key相同的节点以及获得该节点的value。但由于遍历过程中其他线程可能对链表结构做了调整，因此get和containsKey返回的可能是过时的数据，这一点是ConcurrentHashMap在弱一致性上的体现。

### 与JDK1.7相比1.8重大变化

* 取消了segment数组，直接用table保存数据，锁的粒度更小，减少并发冲突的概率。
* 存储数据时采用了链表+红黑树的形式，纯链表的形式时间复杂度为O(n)，红黑树则为O（logn），性能提升很大。
什么时候链表转红黑树？
当key值相等的元素形成的链表中元素个数超过8个的时候。


### 主要数据结构和关键变量

![并发容器_o](https://volc1612.gitee.io/blog/images/并发容器/并发容器_o.png)

使用`Node`类存储`key-value`

![并发容器_o](https://volc1612.gitee.io/blog/images/并发容器/并发容器-p.jpg)

`sizeCtl`：
负数：表示进行初始化或者扩容,-1表示正在初始化，-N，表示有N-1个线程正在进行扩容
正数：0 表示还没有被初始化，>0的数，初始化或者是下一次进行扩容的阈值
`TreeNode`:
用在红黑树，表示树的节点, TreeBin是实际放在table数组中的，代表了这个红黑树的根。